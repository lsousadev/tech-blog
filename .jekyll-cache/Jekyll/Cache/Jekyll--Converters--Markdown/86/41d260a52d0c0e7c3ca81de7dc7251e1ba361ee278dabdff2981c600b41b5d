I"ë~<!--ðŸ”´ ðŸŸ  âš« âšª ðŸŸ£ ðŸŸ¢ ðŸŸ¡ ðŸ”µ-->

<h2 id="api-gateway">API Gateway</h2>

<ul>
  <li>Error codes:
    <ul>
      <li>403: Access denied (authentication or authorization issues)</li>
      <li>429: Limit exceeded or too many requests (throttling)</li>
      <li>502: Incompatible output</li>
      <li>504: INTEGRATION_FAILURE or INTEGRATION_TIMEOUT (default = 29s for all integration types)</li>
    </ul>
  </li>
  <li>Lambda authorizers:
    <ul>
      <li>an API Gateway feature that uses a Lambda function to control access to your API</li>
      <li>takes the callerâ€™s identity as input and returns an IAM policy as output</li>
      <li>token-based: eceives the callerâ€™s identity in a bearer token, such as a JSON Web Token (JWT) or an OAuth token</li>
      <li>request parameter-based: eceives the callerâ€™s identity in a combination of headers, query string parameters, stageVariables, and $context variables</li>
    </ul>
  </li>
  <li>Non-proxy Lambda integration:</li>
</ul>

<p><img src="/assets/images/api_gateway_lambda_integration.png" alt="API Gateway Lambda Integration" /></p>

<h2 id="cloudformation">CloudFormation</h2>

<ul>
  <li>StackSets extends the functionality of stacks by enabling you to create, update, or delete stacks across multiple accounts and regions with a single operation. Using an administrator account, you define and manage an AWS CloudFormation template, and use the template as the basis for provisioning stacks into selected target accounts across specified regions.</li>
  <li>Under the <code class="language-plaintext highlighter-rouge">AWS::Lambda::Function</code> resource, you can use the Code property which contains the deployment package for a Lambda function. For all runtimes, you can specify the location of an object in Amazon S3 (<code class="language-plaintext highlighter-rouge">S3Key</code> and <code class="language-plaintext highlighter-rouge">S3Bucket</code>). For Node.js and Python functions, you can specify the function code inline in the template using <code class="language-plaintext highlighter-rouge">ZipFile</code>.</li>
  <li>The existing Parameters section of a template to define Systems Manager parameters. Systems Manager parameters refer to actual values in the Parameter Store. The value for this type of parameter would be the Systems Manager (SSM) parameter key instead of a string or other value. CloudFormation will fetch values stored against these keys in Systems Manager in your account and use them for the current stack operation.
    <ul>
      <li>As parameters are updated in Systems Manager, you can have the new value of the parameter take effect by just executing a stack update operation.</li>
    </ul>
  </li>
</ul>

<h2 id="cloudwatch">CloudWatch</h2>

<ul>
  <li>Alarms:
    <ul>
      <li>Period: length of time in seconds to evaluate each data point</li>
      <li>Evaluation period: # of most recent periods/data points to evaluate</li>
      <li>Datapoints to alarm: how many breached data points needed in evaluation period to set state to ALARM</li>
    </ul>
  </li>
  <li>CloudWatch does not monitor the memory, swap, and disk space utilization of your instances.</li>
  <li>Monitoring:
    <ul>
      <li>Basic: 5 minutes, N/A for ELB and RDS</li>
      <li>Detailed: 1 minute,  N/A for EBS</li>
      <li>Custom: install CloudWatch agent and configure it to send custom metrics.
        <ul>
          <li>Standard resolution: 1 minute</li>
          <li>High resolution: down to 1 second</li>
        </ul>
      </li>
      <li>Enhanced: Real time metrics for RDS. CloudWatch gathers metrics about CPU utilization from the hypervisor for a DB instance. In contrast, Enhanced Monitoring gathers its metrics from an agent on the DB instance.</li>
    </ul>
  </li>
  <li>RDS logs available via DB parameters:
    <ul>
      <li>Audit log</li>
      <li>Error log (default)</li>
      <li>General log</li>
      <li>Slow query log</li>
    </ul>
  </li>
  <li>Other definitions:
    <ul>
      <li>Dimension: name/value pair that is part of the identity of a metric</li>
      <li>Metric Math: used to query or create time series based on multiple multiple metrics</li>
      <li>Namespace: grouping of metrics aggregated together</li>
    </ul>
  </li>
</ul>

<h2 id="codebuild">CodeBuild</h2>

<ul>
  <li>Fully managed build service that compiles source code, runs tests, and produces software packages that are ready to deploy</li>
</ul>

<h2 id="codecommit">CodeCommit</h2>

<ul>
  <li>Credentials: must have permissions to access AWS resources (such as CodeCommit repositories) and your IAM user, used to manage your Git credentials or the SSH public key for Git connections. With HTTPS connections and Git credentials, you generate a static user name and password in IAM. You then use these credentials with Git and any third-party tool that supports Git user name and password authentication.</li>
</ul>

<h2 id="codedeploy">CodeDeploy</h2>

<ul>
  <li>AppSpec <code class="language-plaintext highlighter-rouge">hooks</code>:
    <ul>
      <li>EC2/on-prem: mappings that link deployment lifecycle event hooks to one or more scripts</li>
      <li>Lambda/ECS: specifies Lambda validation functions to run during a deployment lifecycle event. An AWS Lambda hook is one Lambda function specified with a string on a new line after the name of the lifecycle event. Each hook is executed once per deployment. Two options: <code class="language-plaintext highlighter-rouge">BeforeAllowTraffic</code> and <code class="language-plaintext highlighter-rouge">AfterAllowTraffic</code></li>
    </ul>
  </li>
  <li>CodeDeploy Agent:
    <ul>
      <li>software package that, when installed and configured on an instance, makes it possible for that instance to be used in CodeDeploy deployments</li>
      <li>communicates outbound using HTTPS over port 443</li>
      <li>only needed for EC2/on prem</li>
    </ul>
  </li>
  <li>Automates application deployments to Amazon EC2 instances, on-premises instances, serverless Lambda functions, or Amazon ECS services</li>
  <li>Deployment options:
    <ul>
      <li>In-place: app is stopped, new version is installed, started, and validated. Only for EC2/on-prem</li>
      <li>Blue/Green:
        <ul>
          <li>EC2: original environment is replaced by a different set of instances</li>
          <li>Lambda: only option. Traffic shifted between versions. Functions for testing can be specified. Way traffic shift happens can be chosen.</li>
          <li>ECS: Traffic is shifted from the task set with the original version of a containerized application in an ECS service to a replacement task set in the same service. The protocol and port of a specified load balancer listener are used to reroute production traffic. During deployment, a test listener can be used to serve traffic to the replacement task set while validation tests are run.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="cognito">Cognito</h2>

<ul>
  <li>User Pools: just a user directory</li>
  <li>Sync: a client library that enables cross-device syncing of application-related user data</li>
</ul>

<h2 id="dynamodb">DynamoDB</h2>

<ul>
  <li>Expressions:
    <ul>
      <li>Condition Expression: condition for attribute values to select items to be modified</li>
      <li>Filter Expression: filters whole items off of fetched results before returning result</li>
      <li>Projection Expression: fetch only specified attributes from items</li>
    </ul>
  </li>
  <li>Errors:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">ProvisionedThroughputExceededException</code> - more TPUT (WCU or RCU) used than provisioned</li>
      <li><code class="language-plaintext highlighter-rouge">RequestLimitExceeded</code> - provisioned TPUT exceeds account TPUT limit</li>
      <li><code class="language-plaintext highlighter-rouge">ThrottlingException</code> - rate of requests exceeds allowed TPUT</li>
    </ul>
  </li>
  <li>Operations:
    <ul>
      <li>Atomic counter: implemented via <code class="language-plaintext highlighter-rouge">UpdateItem</code>, increments a numeric attribute unconditionally, can be retried, can fail/duplicate</li>
      <li>Conditional write: good for precise operations, no room for error
        <ul>
          <li>Optimistic Locking: record is locked only when changes are committed to the database. Depends on checking a value upon save to ensure that it has not changed.</li>
          <li>Pessimistic Locking: record is locked while it is edited.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Provisioned throughput math:
    <ul>
      <li>One read request unit represents one strongly consistent read request, or two eventually consistent read requests, for an item up to 4 KB in size</li>
      <li>Transactional read requests require 2 read request units to perform one read for items up to 4 KB</li>
    </ul>
  </li>
  <li>Secondary indexes:
    <ul>
      <li>Global: partition and sort key can both be different from base table. On a provisioned table, GSIâ€™s have their own WCU and RCU. Contains a copy of some or all of the attributes from its base table; you specify which attributes are projected into the GSI when you create the index.</li>
      <li>Local: must have same partition key as base table, different sort key. Called local because the index is made within the partition of the base table. Can only be created on table creation. Contains a copy of some or all of the attributes from its base table; you specify which attributes are projected into the LSI when you create the table.</li>
    </ul>
  </li>
  <li>Streams:
    <ul>
      <li>Kinesis Adapter is recommended way to consume streams from DynamoDB for real-time processing. The DynamoDB Streams API is intentionally similar to that of Kinesis Streams</li>
      <li>Lambda isnâ€™t advised to consume DynamoDB Streams real-time data as it reads records in batches</li>
    </ul>
  </li>
</ul>

<h2 id="ebs">EBS</h2>

<ul>
  <li>New volumes are raw block devices and do not contain any partition or file system.</li>
  <li>Detaching an EBS volume from an EC2 instance:
    <ul>
      <li>terminate instance</li>
      <li>unmount volume or stop instance, then detach
        <ul>
          <li>for root volumes, you must stop instance then detach</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="ec2">EC2</h2>

<ul>
  <li>You can and should use an IAM role to manage temporary credentials for applications that run on an EC2 instance. The role supplies temporary permissions that applications can use when they make calls to other AWS resources. When you launch an EC2 instance, you specify an IAM role to associate with the instance. Applications that run on the instance can then use the role-supplied temporary credentials to sign API requests.
    <ul>
      <li>In order to assign a role to an EC2 instance, you must create an instance profile that is attached to the instance. The instance profile contains the role and can provide the roleâ€™s temporary credentials to an application that runs on the instance.</li>
    </ul>
  </li>
</ul>

<h2 id="ecs">ECS</h2>

<ul>
  <li>Task placement strategy: algorithm for selecting instances for task placement or tasks for termination. Task placement strategies can be specified when either running a task or creating a new service.
    <ul>
      <li>binpack: Place tasks based on the least available amount of CPU or memory. This minimizes the number of instances in use.</li>
      <li>random</li>
      <li>spread: Place tasks evenly based on the specified value. Accepted values are instanceId, host, or a custom attribute key:value pairs such as <code class="language-plaintext highlighter-rouge">attribute:ecs.availability-zone</code>
        <ul>
          <li>Cluster queries are expressions that enable you to group objects. For example, you can group container instances by attributes such as Availability Zone, instance type, or custom metadata. You can add custom metadata to your container instances, known as attributes. Each attribute has a name and an optional string value. You can use the built-in attributes provided by Amazon ECS or define custom attributes.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="elastic-beanstalk">Elastic Beanstalk</h2>

<ul>
  <li>CLI
    <ul>
      <li>deployment: package app as <code class="language-plaintext highlighter-rouge">zip</code> file and deploy with <code class="language-plaintext highlighter-rouge">eb deploy</code></li>
      <li><code class="language-plaintext highlighter-rouge">aws elasticbeanstalk update-application</code> doesnâ€™t allow for package upload, only updates specified properties of the app</li>
    </ul>
  </li>
  <li>Deployment methods (note that <code class="language-plaintext highlighter-rouge">canary</code> is not available):</li>
</ul>

<p><img src="/assets/images/elastic_beanstalk_deployment_methods.png" alt="Elastic Beanstalk Deployment Methods" /></p>

<ul>
  <li>Note that Canary is not available</li>
  <li>Environment: an instance of a version of an application. You can have multiple environments of the same version or app at the same time
    <ul>
      <li>Server environment: composed of an ELB and ASG of EC2 instances containing EB app that writes requests to SQS queue</li>
      <li>Worker environment: composed of an ASG of EC2 instances containing EB app and an SQS daemon that pulls requests from EB SQS queue</li>
    </ul>
  </li>
  <li>Files:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">cron.yaml</code> - configuration file primarily used to define periodic tasks that add jobs to your worker environmentâ€™s queue automatically at a regular interval.</li>
      <li><code class="language-plaintext highlighter-rouge">Dockerrun.aws.json</code> - configuration file primarily used in multicontainer Docker environments hosted in Elastic Beanstalk. This can be used alone or combined with source code and content in a source bundle to create an environment on a Docker platform.</li>
      <li><code class="language-plaintext highlighter-rouge">env.yaml</code> - manifest in the root of your application source bundle to configure the environment name, solution stack and environment links to use when creating your environment. The manifest uses the same format as Saved Configurations.</li>
    </ul>
  </li>
  <li>It isnâ€™t good practice to spin up an RDS instance as part of your EB app as it ties the lifecycle of the database to the lifecycle of app environment. It is better to decouple it by creating an RDS instance separately and configure the app with the necessary information to connect on launch.
    <ul>
      <li>Note that a sec. group cannot be deleted if it is linked to another sec. group by a rule.</li>
    </ul>
  </li>
  <li>Platform Version: New platform versions provide updates to existing software components and support for new features and configuration options. Eg: Java 7 to Java 8
    <ul>
      <li>Two methods to update platform version:
        <ul>
          <li>Update your Environmentâ€™s Platform Version - This is the recommended method when youâ€™re updating to the latest platform version, without a change in runtime, web server, or application server versions, and without a change in the major platform version. This is the most common and routine platform update.</li>
          <li>Blue/Green Deployment - This is the recommended method when youâ€™re updating to a different runtime, web server, or application server versions, or to a different major platform version. This is a good approach when you want to take advantage of new runtime capabilities or the latest Elastic Beanstalk functionality.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Usage: create an application, upload an application version in the form of an application source bundle (for example, a Java .war file) to Elastic Beanstalk, and then provide some information about the application. Elastic Beanstalk automatically launches an environment and creates and configures the AWS resources needed to run your code. After your environment is launched, you can then manage your environment and deploy new application versions.</li>
</ul>

<h2 id="elasticache">Elasticache</h2>

<ul>
  <li>Types:
    <ul>
      <li>Redis: rich features. Blazing fast in-memory data store that provides sub-millisecond latency to power internet-scale real-time applications. Redis also lets you create multiple replicas of a Redis primary. This allows you to scale database reads and to have highly available clusters.</li>
      <li>Memcached: simpler. Less available but can provide multiple threads or cores, whereas Redis is mostly a single-threaded server</li>
    </ul>
  </li>
  <li>Strategies:
    <ul>
      <li>Lazy Loading: write to cache on cache miss</li>
      <li>Russian Doll: nested records with top level cache keys (eg. user, stories, comments)</li>
      <li>Write Through: write to cache on write to database</li>
    </ul>
  </li>
</ul>

<h2 id="kinesis-data-streams">Kinesis Data Streams</h2>

<ul>
  <li>Duplication of data: usually caused by producer or consumer retries, can be mitigated by adding a primary key to the record</li>
  <li>KCL worker (EC2 instance) can process any number of shards, but a shard can only have one record processor (KCL worker)</li>
</ul>

<h2 id="kinesis-data-firehose">Kinesis Data Firehose</h2>

<ul>
  <li>The easiest way to load streaming data into data stores and analytics tools.</li>
  <li>It is a fully managed service that automatically scales to match the throughput of your data.</li>
  <li>It can also batch, compress, and encrypt the data before loading it.</li>
</ul>

<h2 id="kinesis-data-analytics">Kinesis Data Analytics</h2>

<ul>
  <li>Analyze streaming data, gain actionable insights, and respond to your business and customer needs in real time. You can quickly build SQL queries and Java applications using built-in templates and operators for common processing functions to organize, transform, aggregate, and analyze data at any scale.</li>
</ul>

<h2 id="kms">KMS</h2>

<ul>
  <li>Envelope encryption is the practice of encrypting plaintext data with a data key and then encrypting the data key with another top-level master key.
    <ul>
      <li>Encrypting data locally:
    1. Use the <code class="language-plaintext highlighter-rouge">GenerateDataKey</code> operation to get a data encryption key.
    2. Use the plaintext data key (returned in the <code class="language-plaintext highlighter-rouge">Plaintext</code> field of the response) to encrypt data locally, then erase the plaintext data key from memory.
    3. Store the encrypted data key (returned in the <code class="language-plaintext highlighter-rouge">CiphertextBlob</code> field of the response) alongside the locally encrypted data.</li>
      <li>Decrypting data locally:
    1. Use the <code class="language-plaintext highlighter-rouge">Decrypt</code> operation to decrypt the encrypted data key. The operation returns a plaintext copy of the data key.
    2. Use the plaintext data key to decrypt data locally, then erase the plaintext data key from memory.</li>
    </ul>
  </li>
</ul>

<h2 id="lambda">Lambda</h2>

<ul>
  <li>CPU: In the AWS Lambda resource model, you choose the amount of memory you want for your function and are allocated proportional CPU power and other resources. An increase in memory size triggers an equivalent increase in CPU available to your function.</li>
  <li>Concurrency for push-based event sources and invocations:
    <ul>
      <li>concurrent executions = (invocations per second) x (average execution duration in seconds)</li>
      <li>default concurrency limit = 1000/region
        <ul>
          <li>minimum unreserved concurrency per region = 100 (ie. you can reserve 900 between your functions, or one function with 900)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Concurrency for poll-based event source (Kinesis) equals the number of shards.</li>
  <li>Execution context: provides 512 MB of additional disk space in theÂ <code class="language-plaintext highlighter-rouge">/tmp</code> directory. The directory content remains when the execution context is frozen, providing transient cache that can be used for multiple invocations. You can add extra code to check if the cache has the data that you stored.</li>
  <li>Layer: a ZIP archive that contains libraries, a custom runtime, or other dependencies</li>
  <li>InvocationType:
    <ul>
      <li>RequestResponse (Synchronous): default. Connection stays open until function returns something or times out. API response includes the function response</li>
      <li>Event (Asynchronous): events that fail multiple times can be sent to DLQ and API response only includes status code</li>
      <li>Dry-run: validate parameter values and invocation permissions</li>
    </ul>
  </li>
  <li>Runtimes supported: PowerShell, Go, Python, Node.js, Java, C#, Ruby, Custom for everything else</li>
  <li>Traffic Shifting: the <code class="language-plaintext highlighter-rouge">routing-config</code> parameter of a Lambda alias can be implemented for that alias to point to two different versions of a function, as long as they have same IAM exec. role, DLQ config, and none of the versions are $LATEST</li>
</ul>

<h2 id="s3">S3</h2>

<ul>
  <li>CORS config documentâ€™s <code class="language-plaintext highlighter-rouge">&lt;CORSrule&gt;</code> components:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">AllowedOrigin</code> - Specifies domain origins that you allow to make cross-domain requests.</li>
      <li><code class="language-plaintext highlighter-rouge">AllowedMethod</code> - Specifies a type of request you allow (GET, PUT, POST, DELETE, HEAD) in cross-domain requests.</li>
      <li><code class="language-plaintext highlighter-rouge">AllowedHeader</code> - Specifies the headers allowed in a preflight request.</li>
      <li><code class="language-plaintext highlighter-rouge">MaxAgeSeconds</code>  - Specifies the amount of time in seconds (in this example, 3000) that the browser caches an Amazon S3 response to a preflight OPTIONS request for the specified resource. By caching the response, the browser does not have to send preflight requests to Amazon S3 if the original request will be repeated.</li>
      <li><code class="language-plaintext highlighter-rouge">ExposeHeader</code>  - Identifies the response headers (e.g. <code class="language-plaintext highlighter-rouge">x-amz-server-side-encryption</code>, <code class="language-plaintext highlighter-rouge">x-amz-request-id</code>, and <code class="language-plaintext highlighter-rouge">x-amz-id-2</code>) that customers are able to access from their applications (e.g. from a JavaScript <code class="language-plaintext highlighter-rouge">XMLHttpRequest</code> object).</li>
    </ul>
  </li>
  <li>Cross-region replication (CRR) enables automatic, asynchronous copying of objects across buckets in different AWS Regions. Buckets configured for cross-region replication can be owned by the same AWS account or by different accounts. Cross-region replication is enabled with a bucket-level configuration. You add the replication configuration to your source bucket.
    <ul>
      <li>Requirements:
        <ul>
          <li>The source and destination buckets must have versioning enabled.</li>
          <li>The source and destination buckets must be in different AWS Regions.</li>
          <li>Amazon S3 must have permissions to replicate objects from that source bucket to the destination bucket on your behalf.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Encryption:
    <ul>
      <li>SSE-S3 - header: <code class="language-plaintext highlighter-rouge">x-amz-server-side-encryption</code> (example value: <code class="language-plaintext highlighter-rouge">AES256</code>)</li>
      <li>SSE-KMS
        <ul>
          <li>headers:
            <ul>
              <li><code class="language-plaintext highlighter-rouge">x-amz-server-side-encryption</code> (value <code class="language-plaintext highlighter-rouge">aws:kms</code>)</li>
              <li><code class="language-plaintext highlighter-rouge">x-amz-server-side-encryption-aws-kms-key-id</code> (optional, defaults to default CMK for region, which is created automatically by S3)</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>SSE-C: customer-provider encryption keys
        <ul>
          <li>headers:
            <ul>
              <li><code class="language-plaintext highlighter-rouge">x-amz-server-side-encryption-customer-algorithm</code></li>
              <li><code class="language-plaintext highlighter-rouge">x-amz-server-side-encryption-customer-key</code></li>
              <li><code class="language-plaintext highlighter-rouge">x-amz-server-side-encryption-customer-key-MD5</code></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Glacier object retrieval:
    <ul>
      <li>Standard: 3-5 hours</li>
      <li>Bulk: 5-12 hours</li>
      <li>Expedited: 1-5 minutes</li>
    </ul>
  </li>
  <li>Multipart Upload: when using a KMS customer master key (CMK), the requester must have permission to the <code class="language-plaintext highlighter-rouge">kms:Decrypt</code> and <code class="language-plaintext highlighter-rouge">kms:GenerateDataKey*</code> actions on the key. These permissions are required because Amazon S3 must decrypt and read data from the encrypted file parts before it completes the multipart upload.</li>
  <li>S3 Transfer Acceleration leverages Amazon CloudFrontâ€™s globally distributed AWS Edge Locations. As data arrives at an AWS Edge Location, data is routed to your Amazon S3 bucket over an optimized network path.</li>
</ul>

<h2 id="sam">SAM</h2>

<ul>
  <li>Consists of the AWS SAM template specification that you use to define your serverless applications, and the AWS SAM command line interface (AWS SAM CLI) that you use to build, test, and deploy your serverless applications. The CLI provides a Lambda-like execution environment locally. It helps you catch issues upfront by providing parity with the actual Lambda execution environment.</li>
</ul>

<h2 id="sqs">SQS</h2>

<ul>
  <li>Delay queue lets you postpone the delivery of new messages to a queue for a number of seconds. If you create a delay queue, any messages that you send to the queue remain invisible to consumers for the duration of the delay period. The default (minimum) delay for a queue is 0 seconds. The maximum is 15 minutes</li>
  <li>Long polling is a way to retrieve messages from your Amazon SQS queues. While the regular short polling returns immediately, even if the message queue being polled is empty, long polling doesnâ€™t return a response until a message arrives in the message queue, or the long poll times out.</li>
</ul>

<h2 id="sts">STS</h2>

<ul>
  <li>API calls:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">AssumeRole</code> - needs a role ARN as parameter and returns the temporary credentials to a newly created session with same policies/access as the role.</li>
      <li><code class="language-plaintext highlighter-rouge">AssumeRoleWithSAML</code> - same as above but for users authenticated via SAML, eg. enterprise identity store or directory.</li>
      <li><code class="language-plaintext highlighter-rouge">AssumeRoleWithWebIdentity</code> - same as above but for federated users authenticated via public identity providers such as Google.</li>
      <li><code class="language-plaintext highlighter-rouge">GetFederationToken</code> - doesnâ€™t support MFA.</li>
      <li><code class="language-plaintext highlighter-rouge">GetSessionToken</code> - returns set of temporary credentials for accounts and users only. The credentials consist of an access key ID, a secret access key, and a security token. Typically used for MFA.</li>
    </ul>
  </li>
</ul>

<h2 id="systems-manager-parameter-store">Systems Manager Parameter Store</h2>

<ul>
  <li>Provides secure, hierarchical storage for configuration data management and secrets management</li>
</ul>

<h2 id="vpc">VPC</h2>

<ul>
  <li>Route tables:
    <ul>
      <li>default limit of 200 route tables per VPC</li>
      <li>you can associate multiple subnets to the same route table</li>
      <li>you cannot modify/edit the main route created by default</li>
      <li>a subnet can only be associated with one route table at a time</li>
    </ul>
  </li>
</ul>

<h2 id="x-ray">X-Ray</h2>

<ul>
  <li>Active Tracing: feature you can enable in Lambda</li>
  <li>Components:
    <ul>
      <li>Annotation: key-value pairs added to traces, segments, and subsegments and are indexed for filter expression searches</li>
      <li>Metadata: same as annotation but not indexed</li>
      <li>Sampling algorithm: default is 1st request of every second + 5% of remaining requests</li>
      <li>Segment: provides the name of compute resource handling request, details about request and work done
        <ul>
          <li>host - host name, alias or IP address</li>
          <li>request - method, client address, path, user agent</li>
          <li>response - status, content</li>
          <li>work done - start and end time, subsegments</li>
          <li>issues - errors, faults, exceptions</li>
        </ul>
      </li>
      <li>Subsegment: additional details about work done
        <ul>
          <li>namespace: field in subsegment. <code class="language-plaintext highlighter-rouge">aws</code> for AWS SDK calls; <code class="language-plaintext highlighter-rouge">remote</code> for other downstream calls</li>
          <li>http: http object with information about an outgoing HTTP call</li>
          <li>aws: aws object with information about the downstream AWS resource that your application called.</li>
          <li>annotation, metadata</li>
          <li>error, throttle, fault, and cause</li>
          <li>precursor_ids: array of subsegment IDs that identifies subsegments with the same parent that completed prior to this subsegment</li>
        </ul>
      </li>
      <li>Trace: string of segments generated by a single request</li>
      <li>Tracing header: added in the HTTP request header (not on the segment document). A tracing header (<code class="language-plaintext highlighter-rouge">X-Amzn-Trace-Id</code>) can originate from the X-Ray SDK, an AWS service, or the client request</li>
    </ul>
  </li>
  <li>ECS:
    <ul>
      <li>create a Docker image that runs the X-Ray daemon</li>
      <li>upload it to a Docker image repository</li>
      <li>deploy it to your Amazon ECS cluster</li>
      <li>use port mappings and network mode settings in your task definition file to allow your application to communicate with the daemon container
        <ul>
          <li>the daemon is a software application that listens for traffic on UDP port 2000, gathers raw segment data, and relays it to the AWS X-Ray API</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Enabling X-Ray:
    <ul>
      <li>Elastic Beanstalk: include xray-daemon.config file in .ebextensions directory of source code or via console</li>
      <li>ECS: create a docker image that runs the X-Ray daemon</li>
    </ul>
  </li>
  <li>Environment variables used by Lambda to facilitate communication with the X-Ray daemon and configure the X-Ray SDK:
    <ul>
      <li>_X_AMZN_TRACE_ID: contains tracing header (sampling decision, tracing ID, parent segment ID)</li>
      <li>AWS_XRAY_CONTEXT_MISSING: used by SDK to determine what to do if no tracing header. Set by Lambda to LOG_ERROR by default</li>
      <li>AWS_XRAY_DAEMON_ADDRESS: formatted IP_ADDRESS:PORT and used to send trace data to daemon directly, without SDK</li>
    </ul>
  </li>
  <li>If a load balancer or other intermediary forwards a request to your application, X-Ray takes the client IP from the <code class="language-plaintext highlighter-rouge">X-Forwarded-For</code> header in the request instead of from the source IP in the IP packet, which would only show the ELBâ€™s IP address.</li>
  <li>SDK: does not send trace data directly to AWS X-Ray. To avoid calling the service every time your application serves a request, the SDK sends the trace data to a daemon, which collects segments for multiple requests and uploads them in batches.</li>
</ul>
:ET